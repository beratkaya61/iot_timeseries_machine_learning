{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ETTh2 dataset loaded from local file!\n",
      "                  date       HUFL    HULL       MUFL   MULL   LUFL   LULL  \\\n",
      "0  2016-07-01 00:00:00  41.130001  12.481  36.535999  9.355  4.424  1.311   \n",
      "1  2016-07-01 01:00:00  37.528000  10.136  33.936001  7.532  4.435  1.215   \n",
      "2  2016-07-01 02:00:00  37.946999  11.309  35.330002  9.007  2.100  0.000   \n",
      "3  2016-07-01 03:00:00  38.952000  11.895  35.543999  9.436  3.380  1.215   \n",
      "4  2016-07-01 04:00:00  38.113998  11.476  35.410000  9.623  2.036  0.000   \n",
      "\n",
      "          OT  \n",
      "0  38.661999  \n",
      "1  37.124001  \n",
      "2  36.465000  \n",
      "3  33.608501  \n",
      "4  31.850500  \n"
     ]
    }
   ],
   "source": [
    "# üìÇ 1. Load ETTh2 Data from local file\n",
    "file_path = \"../data/raw/ETTh2.csv\"\n",
    "\n",
    "df_etth2 = pd.read_csv(file_path)\n",
    "\n",
    "print(\"‚úÖ ETTh2 dataset loaded from local file!\")\n",
    "print(df_etth2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Preprocessing applied (normalization)!\n",
      "                  date        OT\n",
      "0  2016-07-01 00:00:00  0.853355\n",
      "1  2016-07-01 01:00:00  0.822649\n",
      "2  2016-07-01 02:00:00  0.809491\n",
      "3  2016-07-01 03:00:00  0.752461\n",
      "4  2016-07-01 04:00:00  0.717362\n"
     ]
    }
   ],
   "source": [
    "# üìú 2. Preprocessing\n",
    "# ‚ùó IMPORTANT: These min and max values must be same as ETTh1 preprocessing min-max\n",
    "# Update them according to your preprocessing!\n",
    "\n",
    "file_path_etth1 = \"../data/raw/ETTh1.csv\"\n",
    "\n",
    "df_etth1 = pd.read_csv(file_path_etth1)\n",
    "\n",
    "# Get min and max for 'OT' column\n",
    "min_OT = df_etth1['OT'].min()\n",
    "max_OT = df_etth1['OT'].max()\n",
    "\n",
    "df_etth2['OT'] = (df_etth2['OT'] - min_OT) / (max_OT - min_OT)\n",
    "\n",
    "print(\"\\n‚úÖ Preprocessing applied (normalization)!\")\n",
    "print(df_etth2[['date', 'OT']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ FastAPI Server URL\n",
    "fastapi_url = \"http://localhost:8000/predict\"\n",
    "\n",
    "# üß† Rolling window for 96 sensor readings\n",
    "rolling_window = []\n",
    "\n",
    "# üìà Stream row by row\n",
    "for idx, row in df_etth2.iterrows():\n",
    "    # Add new value to the window\n",
    "    ot_value = row['OT']\n",
    "    rolling_window.append(ot_value)\n",
    "\n",
    "    # Keep only the last 96 points\n",
    "    if len(rolling_window) > 96:\n",
    "        rolling_window.pop(0)\n",
    "\n",
    "    # Predict only when we have 96 points\n",
    "    if len(rolling_window) == 96:\n",
    "        # Convert rolling_window values to Python native types (e.g., float)\n",
    "        payload = {\n",
    "            \"sensor_values\": [float(value) for value in rolling_window]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(fastapi_url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            preds = response.json()\n",
    "\n",
    "            # üìã Print results\n",
    "            print(\"\\nüéØ Prediction Results:\")\n",
    "            for model, pred in preds.items():\n",
    "                print(f\"{model}: {pred:.6f}\")\n",
    "         \n",
    "            #split with print\n",
    "            print(\"-------------------------------------------------\")\n",
    "\n",
    "            print(f\"\\nüïí Time: {row['date']}\")\n",
    "            print(f\"LSTM Prediction: {preds['LSTM_Prediction']:.6f}\")\n",
    "            print(f\"PatchTST Prediction: {preds['PatchTST_Prediction']:.6f}\")\n",
    "            print(f\"LLM Prediction: {preds['LLM_Prediction']:.6f}\")\n",
    "            print(f\"Final Ensemble Prediction: {preds['Final_Ensembled_Prediction']:.6f}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Request failed: {e}\")\n",
    "\n",
    "    # ‚è≥ Wait for 1 second to simulate real-time\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n‚úÖ Test finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
